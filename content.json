{"meta":{"title":"Technical blog","subtitle":"IT小白的成长之旅","description":"请乐观，请珍惜","author":"Li Yudong","url":"http://yoursite.com","root":"/"},"pages":[{"title":"广告位招租","date":"2020-08-16T15:01:00.000Z","updated":"2020-08-16T15:02:08.971Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-08-16T14:49:27.000Z","updated":"2020-08-16T14:52:47.789Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"archives","date":"2020-08-16T14:58:35.000Z","updated":"2020-08-16T14:58:35.251Z","comments":true,"path":"archives/index.html","permalink":"http://yoursite.com/archives/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-08-16T14:45:00.000Z","updated":"2020-08-16T14:48:55.034Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MXNET机器学习初见","slug":"机器学习初见","date":"2020-08-19T15:28:46.000Z","updated":"2020-08-19T17:12:43.783Z","comments":true,"path":"2020/08/19/机器学习初见/","link":"","permalink":"http://yoursite.com/2020/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%A7%81/","excerpt":"","text":"1、基础知识NDArray、NumPy的广播机制：1、数组维度不同，后缘维度的轴长（从末尾算起的维度）相同；（4，3）+（3，）；（3，4，2）+（4，2） 2、数组维度相同，其中有个轴为1；（4，3）+（4，1）：在1轴上广播扩展。 NDArray,NumPy的相互变换： 123P = np.ones((2,3))D = nd.array(P)D.asnumpy() 自动求梯度（gradient），MXNET中使用autograd模块自动求梯度： 12345x = nd.arange(4).reshape((4,1))x.attach_grad() #申请内存with autograd.record(): y = 2 * nd.dot(x.T,x) #若y为标量，贼会默认对y元素求和后，求关于X的梯度y.backward() uniform:均匀分布采样；normal:正态分布采样；poisson:泊松分布采样。 2、线性回归损失函数：平方函数，平方损失；在模型训练中，希望找到一组模型参数为w1,w2,b使得训练样本平均损失最小。 解析解：误差最小化问题的解刚好可用数学公式表达出来；大多数为数值解，只能利用优化算法有限次迭代模型参数，从而尽可能降低损失函数的值。 全连接层：又名稠密层，输出层中的神经元与输入层中的各个输入完全连接； 矢量计算比标量逐个相加更加省时间，故往往利用矢量矩阵运算来实现深度学习； 优化算法：小批量随机梯度下降：批量大小batch size,学习率n均为超参数，为人为设定并非模型学习出来的， 调参：通过反复试错来寻找合适的超参数， 123def sgd(params,lr,batch_size): #sgd函数实现小批量随机梯度下降算法 for param in params: param[:] = param - lr * param.grad / batch_size 在一个迭代周期epoch中，将完整遍历一遍data_iter函数，并对训练数据集中所有样本都使用一次。 Gluon简洁实现：1、提供data包来读取数据： 2、提供大量预定义层，nn模块：neural networks： 123from mxnet.gluon import nnnet = nn.Sequential() #Sequential实例是串联各层的容器，依次添加层，每一层一次计算并作为下一层输入net.add(nn.Dense(1)) #Dense全连接层，GLUON无须指定各层形状，模型会自动推断 3、利用init模块来实现模型参数初始化的各种方法： 12from mxnet.gluon import initnet.initialize(init.Normal(sigma=0.01)) #均值为0，标准差0.01的正态分布 4、定义损失函数：利用loss模块： 12from mxnet.gluon import loss as glossloss = gloss.L2Loss() #平方损失又是L2范数损失 5、定义优化算法：创建Trainer实例","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"初学者","slug":"初学者","permalink":"http://yoursite.com/tags/%E5%88%9D%E5%AD%A6%E8%80%85/"}]},{"title":"C++四天入门","slug":"C-四天入门","date":"2020-08-19T10:14:31.000Z","updated":"2020-08-19T15:22:03.380Z","comments":true,"path":"2020/08/19/C-四天入门/","link":"","permalink":"http://yoursite.com/2020/08/19/C-%E5%9B%9B%E5%A4%A9%E5%85%A5%E9%97%A8/","excerpt":"","text":"Day One 基础架构1、数组与函数的关系数组与函数并无本质区别，均是一种映射的形式。变量函数，指针数组。 数组：展开的函数，关键在于指针变化，查询时间快。 函数：压缩的数组，关键在于值传递，用INDEX来定位，所用空间小。 算法中的时空互换逻辑，时间复杂度与空间复杂度可以一定程度互换。 2、C++的编程逻辑面向过程：自顶向下的编程，性能高，但需要处理实现性能的每一个细节，难以复用、扩展。 面向对象：抽象化事物，建立模型。 函数式编程：强调将计算过程分解成可复用的函数，MAP方法。 1auto add = [](int a,int b) -&gt; int &#123;return a+b&#125;; 泛型编程：STL，编写完全一般化并可重复使用的算法，其效率与针对某特定数据类型而设计的算法相同；泛型：在多种数据类型上皆可操作；将算法与数据结构完全分离。 123template &lt;typename T,typename U&gt;auto add(T a, U, b) -&gt; decltype(a+b)return a + b 3、程序执行的底层C源码—编译—》对象文件—链接—》可执行程序 编译时：语法检查，一个源码生成一个目标文件 对象文件：存储各种各样定义 链接：需将所有对象文件定义捏合在一起 定义：函数具体的实现过程在这（有地址空间的为定义） 声明：说有这样一个东西（无地址空间为声明），作用于编译阶段用于语法检查，在调用函数时做语法检查，仅包含函数传入参数与返回值，并不关心函数内部 nm -C main.O 查看main.O该对象文件内容，main.O中printf由系统库实现，add由自定库实现 为何要分开定义与声明？ .h头文件—》放置声明 源文件—》放置定义；把定义放在头文件往往会产生bug apt-get install vim.deb; ctrl +t 打开中断 凡是未定义（undefined）、冲突（duplicate:符号定义有2个）的错误—》一般是链接阶段的错误； 4、google测试框架要实现第三方模块功能的引入—》引入头文件 .h 其定义压缩在一起生成了库文件：静态链接库： .lib IDE：集成开发环境=文本(vim,gcc) + 编译(g++) + 调试(gdb,lldb)","categories":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/categories/C/"}],"tags":[{"name":"初学者","slug":"初学者","permalink":"http://yoursite.com/tags/%E5%88%9D%E5%AD%A6%E8%80%85/"}]},{"title":"基于HEXO的博客搭建","slug":"首篇博文","date":"2020-08-15T11:11:49.000Z","updated":"2020-08-19T15:26:07.429Z","comments":true,"path":"2020/08/15/首篇博文/","link":"","permalink":"http://yoursite.com/2020/08/15/%E9%A6%96%E7%AF%87%E5%8D%9A%E6%96%87/","excerpt":"","text":"环境准备1、Git下载并利用SSH密钥关联上GitHub账号 2、JS.node下载 3、npm、cnpm、hexo下载 创建博客并利用GitHub Pages上传网络端1、创建空文件夹，并使用hexo init 生成博客 2、利用GitHub生成新的仓库作为博客资源，在原blog文件夹下安装GIT，并部署至该仓库","categories":[{"name":"前端页面","slug":"前端页面","permalink":"http://yoursite.com/categories/%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2/"}],"tags":[{"name":"初学者","slug":"初学者","permalink":"http://yoursite.com/tags/%E5%88%9D%E5%AD%A6%E8%80%85/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-08-15T11:06:14.903Z","updated":"2020-08-15T11:06:14.904Z","comments":true,"path":"2020/08/15/hello-world/","link":"","permalink":"http://yoursite.com/2020/08/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/categories/C/"},{"name":"前端页面","slug":"前端页面","permalink":"http://yoursite.com/categories/%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2/"}],"tags":[{"name":"初学者","slug":"初学者","permalink":"http://yoursite.com/tags/%E5%88%9D%E5%AD%A6%E8%80%85/"}]}
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E6%AD%A6%E6%B1%8932x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E6%AD%A6%E6%B1%8916x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib1/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="在卷积神经网络中介绍了计算机视觉领域常用的深度学习模型，并实践了简单的图像分类。先描述目标检测的流程与方法，再使用全卷积网络对图像做语义分割，之后用样式迁移技术生成图像。 图像增广1、扩大样本数据集；2、随机改变训练样本可降低模型对某些属性的依赖。两者均为了提高模型的泛化性。 常用方法：翻转和裁剪、变化颜色、叠加多个图像增广方法； 为了在预测时获得准确结果，图像增广通常仅用于训练集，而不在预测时使">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机视觉">
<meta property="og:url" content="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.html">
<meta property="og:site_name" content="Technical blog">
<meta property="og:description" content="在卷积神经网络中介绍了计算机视觉领域常用的深度学习模型，并实践了简单的图像分类。先描述目标检测的流程与方法，再使用全卷积网络对图像做语义分割，之后用样式迁移技术生成图像。 图像增广1、扩大样本数据集；2、随机改变训练样本可降低模型对某些属性的依赖。两者均为了提高模型的泛化性。 常用方法：翻转和裁剪、变化颜色、叠加多个图像增广方法； 为了在预测时获得准确结果，图像增广通常仅用于训练集，而不在预测时使">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SSD%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B.png">
<meta property="og:image" content="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/R-CNN.png">
<meta property="og:image" content="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB.png">
<meta property="article:published_time" content="2020-08-28T10:44:52.000Z">
<meta property="article:modified_time" content="2020-08-29T11:01:56.399Z">
<meta property="article:author" content="Li Yudong">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SSD%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B.png">

<link rel="canonical" href="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>计算机视觉 | Technical blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Technical blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">IT小白的成长之旅</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">2</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">5</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">16</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/tiarmor1" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/author.jpg">
      <meta itemprop="name" content="Li Yudong">
      <meta itemprop="description" content="请乐观，请珍惜">
    </span>
    
    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Technical blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          计算机视觉
        </h1>
    
        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
    
              <time title="创建时间：2020-08-28 18:44:52" itemprop="dateCreated datePublished" datetime="2020-08-28T18:44:52+08:00">2020-08-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-29 19:01:56" itemprop="dateModified" datetime="2020-08-29T19:01:56+08:00">2020-08-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>
    
          
    
        </div>
      </header>
    
    
    
    
    <div class="post-body" itemprop="articleBody">
    
      
        <p>在卷积神经网络中介绍了计算机视觉领域常用的深度学习模型，并实践了简单的图像分类。先描述目标检测的流程与方法，再使用全卷积网络对图像做语义分割，之后用样式迁移技术生成图像。</p>
<h2 id="图像增广"><a href="#图像增广" class="headerlink" title="图像增广"></a>图像增广</h2><p>1、扩大样本数据集；2、随机改变训练样本可降低模型对某些属性的依赖。两者均为了提高模型的泛化性。</p>
<p>常用方法：翻转和裁剪、变化颜色、叠加多个图像增广方法；</p>
<p>为了在预测时获得准确结果，图像增广通常仅用于训练集，而不在预测时使用含随机操作的图像增广。</p>
<p>Gluon数据集提供的transform模块中，transform_first函数将图像增广应用在每个训练样本（图像和标签）的第一个元素，即图像之上。</p>
<h3 id="用增广后图像训练模型："><a href="#用增广后图像训练模型：" class="headerlink" title="用增广后图像训练模型："></a>用增广后图像训练模型：</h3><p>1、定义try_all_gpus函数，获取所有能用的GPU；</p>
<p>2、定义辅助函数_get_batch将小批量数据样本batch划分，并复制到ctx变量所指定的各个显存上；</p>
<p>3、定义evaluate_accuracy函数来评价模型的分类准确性，该函数通过辅助函数_get_batch使用ctx变量所包含的所有GPU来评价模型；</p>
<p>4、定义train函数使用多GPU训练并评价模型；</p>
<p>5、最终定义train_with_data_aug函数，来使用图像增广来训练模型；该函数获取所有GPU，并将Adam算法作为训练优化算法，之后将图像增广应用于训练数据集上，最后调用刚定义的train函数训练并评价模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_with_data_aug</span>(<span class="params">train_augs, test_augs, lr = <span class="number">0.001</span></span>):</span></span><br><span class="line">    batch_size, ctx, net = <span class="number">256</span>, try_all_gpus(), d2l.resnet18(<span class="number">10</span>)</span><br><span class="line">    net.initialize(ctx=ctx, init=init.Xavier())</span><br><span class="line">    trainer = gluon.Trainer(net.collect_params(), <span class="string">&#x27;adam&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: lr&#125;)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    train_iter = load_cifar10(<span class="literal">True</span>, train_augs, batch_size)</span><br><span class="line">    test_iter = load_cifar10(<span class="literal">False</span>, test_augs, batch_size)</span><br><span class="line">    train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>





<h2 id="图像微调"><a href="#图像微调" class="headerlink" title="图像微调"></a>图像微调</h2><p>由于收集数据所需要的成本较高，应用迁移学习：将从源数据集学到的知识迁移到目标数据集上。例：可从图形数据集训练的模型中抽取较通用的模型特征，边缘、纹理、形状、物体组成识别等等。</p>
<p>微调时常用的一种迁移学习技术，当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力，步骤包括：</p>
<p>1、在源数据集上预训练一个神经网络模型，即源模型；</p>
<p>2、创建一个新的神经网络模型，即目标模型，其复制了源模型上除了输出层以外的所有模型设计与参数。假设该模型参数包含了源数据集上学习到的知识，且同样适用于目标数据集。</p>
<p>3、为目标模型添加一个输出大小为目标数据集类别个数的输出层，并初始化该层的模型参数。</p>
<p>4、在目标数据集上训练目标模型，将从头训练输出层，而其余层的参数将会基于源模型的参数微调得到。</p>
<h3 id="热狗识别"><a href="#热狗识别" class="headerlink" title="热狗识别"></a>热狗识别</h3><p>基于一个小数据集对在ImageNet数据集上训练好的ResNet模型进行微调。</p>
<p>1、获取数据集；</p>
<p>2、定义和初始化模型：使用在ImageNet数据集上预训练的ResNet-18作为源模型，该源模型实例含有两个成员变量，即features和output。前者包括模型输出层以外的所有层，后者为模型的输出层，这样的划分方便微调除输出层以外所有层的模型参数。</p>
<p>3、微调模型：先定义一个使用微调的训练函数train_fine_tuning，以便多次调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fine_tuning</span>(<span class="params">net, learning_rate, batch_size=<span class="number">128</span>, num_epochs=<span class="number">5</span></span>):</span></span><br><span class="line">    train_iter = gdata.DataLoader(train_imgs.transform_first(train_augs), batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = gdata.DataLoader(test_imgs.transform_first(test_augs), batch_size)</span><br><span class="line">    ctx = d2l.try_all_gpus()</span><br><span class="line">    net.collect_params().reset_ctx(ctx)</span><br><span class="line">    net.hybridize()</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    trainer = gluon.Trainer(net.collect_params(), <span class="string">&#x27;sgd&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: learning_rate, <span class="string">&#x27;wd&#x27;</span>: <span class="number">0.001</span>&#125;)</span><br><span class="line">    d2l.train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)</span><br></pre></td></tr></table></figure>

<p>一般来说，微调参数会使用较小的学习率；而从头训练输出层可以使用较大学习率。</p>
<h2 id="目标检测与边界框"><a href="#目标检测与边界框" class="headerlink" title="目标检测与边界框"></a>目标检测与边界框</h2><p>在图像分类任务里，假设只有一个主体目标；而目标检测往往是图像中有多个感兴趣的目标。</p>
<p>目标检测算法通常会在输入图像中采样大量的区域，，然后判断是否包含感兴趣的目标，并调整区域边缘从而更准确地预测目标的真是边界框。</p>
<p>锚框：以每个像素为中心生成多个大小和宽高比不同的边界框。</p>
<p>交并比：（若某个锚框较好地覆盖了图像的狗，那么较好该如何量化）直观的方法是，衡量锚框与真实边界框间的相似度Jaccard系数可以衡量两个集合的相似度，Jaccard系数等于二者交集大小除以二者并集大小。</p>
<p>在训练集中，将每一个锚框视为一个训练样本，为了训练目标检测模型，需为每个锚框标注两个标签：1、锚框所含目标的类别；2、真实边界框相对锚框的便宜量offset。</p>
<p>在目标检测的训练集中，每个图像已经标注了真实边界框的位置及所含目标的类别，那么生成锚框后，如何为锚框分配与其相似的真实边界框呢？</p>
<h3 id="分配真实边界框"><a href="#分配真实边界框" class="headerlink" title="分配真实边界框"></a>分配真实边界框</h3><p>1、锚框有Na个，真实边界框有Nb个，定义矩阵为Na X Nb，其第i列第j行的元素为锚框Ai与真实边界框Bj的交并比。则通过不停找出矩阵最大元素，且每找出一个元素则丢弃该行列的元素，直至矩阵丢弃完，只剩Na - Nb个锚框。</p>
<p>2、遍历剩下的锚框，只有该交并比大于预先设定的阈值时，才为锚框分配真实边界框Bj。</p>
<p>3、如果一个锚框A被分配了真实边界框B，将A的类别设为B的类别，并根据B和A的中心坐标的相对位置以及两个框的相对大小为锚框A标注偏移量。如果一个锚框没有被分配真实边界框，需将该锚框的类别设为背景，称为负类锚框。</p>
<p>4、通过contrib.nd模块中的MultiBoxTarget函数来为锚框标注偏移量和类别。该函数将背景设定为0，并从令0开始的目标类别的整数索引自加1，并通过expand_dims函数为锚框和真实边界添加样本维，并构造形状为（批量大小，包括背景的类别个数，锚框数）的任意预测结果。</p>
<h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>当锚框数量较多时，同一目标可能输出较多相似的。用非极大值抑制来移除：对一个预测边界框B，模型会计算其各个类别的预测概率，其中最大概率对应的类别即B的预测类别，且在同一图像上将预测类别置信度从高到低排列，得到列表L。从L中选取置信度最高的预测边界框B1为基准，将与B1交并比大于某阈值的从L中移除，阈值为预定的超参数，此时L保留了置信度最高的边界框并移除了与之相似的其他预测边界框。</p>
<p>多尺度目标检测</p>
<p>如果以图像每个像素中心都生成锚框，很容易生成过多锚框而造成计算量过大，方法一：在输入图像中均匀采样一小部分像素，并以采样的像素为中心生成锚框。之后既然我们已经在不同尺度下生成了不同大小的锚框，相应的需要在不同尺度下检测不同大小的目标，基于卷积神经网络有如下的方法：</p>
<p>在某尺度下，假设我们根据Ci张形状为h X w的特征图生成h X w组不同中心的锚框，且每组锚框的个数为a。</p>
<p>假设这里的Ci张特征图为卷积神经网络根据输入图像做前向运算所得的中间输出，根据感受野的定义，特征图在相同位置的Ci个单元在输入图像的感受野相同且表征了同一感受野内的输入图像信息。因此我们将这Ci个单元变换为该位置为中心生成的a个锚框的类别和偏移量，故本质上使用感受野内的信息来预测锚框。</p>
<p>因此不同大小的感受野用于检测不同大小的目标，可通过设计网络来控制输出层感受野大小，从而分别用来检测不同大小的目标。</p>
<h3 id="单发多框检测"><a href="#单发多框检测" class="headerlink" title="单发多框检测"></a>单发多框检测</h3><p>由一个基础网络块和若干多尺度特征块串联而成。其中网络块用于从原始图像中抽取特征，因此一般会选择常用的深度卷积神经网络，例如：在分类层之前截断的VGG、或者用ResNet替代。</p>
<p><img src="/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SSD%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B.png" alt="SSD单发多框检测"></p>
<p>设计基础网络，使其输出的高宽较大，这样一来基于该特征图生成的锚框数量较多，用于检测较小目标；接下来每个多尺度特征块将上一层提供的特征图的高、宽减小，使感受野变广阔，这样越靠顶部其特征图越小，生成锚框越少，适合检测尺寸大的目标。借此，单发多框检测是一个多尺度的目标检测。</p>
<h4 id="类别预测层"><a href="#类别预测层" class="headerlink" title="类别预测层"></a>类别预测层</h4><p>如果用全连接层作为输出，容易导致模型参数过多，故像NIN一样使用卷积层的通道进行输出类别的预测，来降低模型复杂度。即使用一个保持输入高、宽的卷积层，使输入、输出的空间坐标一一对应</p>
<h4 id="边界预测层"><a href="#边界预测层" class="headerlink" title="边界预测层"></a>边界预测层</h4><p>设计与类预测层类似，需要为每个锚框预测4个偏移量。</p>
<h4 id="连接多尺度的预测"><a href="#连接多尺度的预测" class="headerlink" title="连接多尺度的预测"></a>连接多尺度的预测</h4><p>由于每个尺度的特征图形状与锚框个数都可能不同，因此不同尺度预测输出形状可能不同。需要将他们变形成统一的格式并将多尺度的预测连结，从而让后续的计算更简单。</p>
<h4 id="高、宽减半块"><a href="#高、宽减半块" class="headerlink" title="高、宽减半块"></a>高、宽减半块</h4><p>为了能多尺度地检测目标，需要定义高宽减半块，其串联了两个填充为1的3X3卷积层和步幅为2的2X2最大池化层，卷积层不改变特征图形状，而后面池化层将特征图的高、宽减半。</p>
<h4 id="基础网络块"><a href="#基础网络块" class="headerlink" title="基础网络块"></a>基础网络块</h4><p>用于在原始图像中抽取特征，此处串联3个高、宽减半块，并将通道数翻倍，则当输入图像形状为256X256时，基础网络块的输出特征图的形状为32X32。</p>
<h4 id="完整的模型"><a href="#完整的模型" class="headerlink" title="完整的模型"></a>完整的模型</h4><p>单发多框检测一共包括5个模块，每个模块即生成锚框，又来预测锚框的类别与偏移量。第一模块为基础网络块，二至四模块为高宽减半块，第五模块使用全局最大池化层将高和宽降到1。</p>
<h3 id="单发多框检测训练模型"><a href="#单发多框检测训练模型" class="headerlink" title="单发多框检测训练模型"></a>单发多框检测训练模型</h3><h4 id="1、读取数据集并初始化；"><a href="#1、读取数据集并初始化；" class="headerlink" title="1、读取数据集并初始化；"></a>1、读取数据集并初始化；</h4><h4 id="2、定义损失函数与评价函数："><a href="#2、定义损失函数与评价函数：" class="headerlink" title="2、定义损失函数与评价函数："></a>2、定义损失函数与评价函数：</h4><p>一、有关锚框类别的损失，图像分类问题一般使用的：交叉熵函数</p>
<p>二、有关正类锚框偏移量的损失：预测偏移量是一个回归问题，因此不用平方损失，而用L1范数损失，即预测值与真实值之间差的绝对值。</p>
<h4 id="3、训练模型"><a href="#3、训练模型" class="headerlink" title="3、训练模型"></a>3、训练模型</h4><p>在模型的前向计算过程中生成多尺度的锚框anchors，并为每个锚框预测类别cls_preds和偏移量bbox_preds，之后根据标签信息Y为生成的每个锚框标注类别和偏移量。最后，根据这两者值来计算损失函数。</p>
<h4 id="4、预测目标"><a href="#4、预测目标" class="headerlink" title="4、预测目标"></a>4、预测目标</h4><p>在预测阶段，我们读取图像并变换尺寸，转换为卷积层所需的四维格式，通过MultiBoxDetection函数根据锚框及其预测偏移量得到预测边界框，并通过非极大值抑制移除相似的预测边界框；最后，将置信度不低于0.3的边界框筛选为最终输出。</p>
<h2 id="区域卷积神经网络R-CNN"><a href="#区域卷积神经网络R-CNN" class="headerlink" title="区域卷积神经网络R-CNN"></a>区域卷积神经网络R-CNN</h2><p>R-CNN首先对图像选取若干提议区域，并标注它们的类别和边界框，之后用卷积神经网络对每个提议区域做前向运算来抽取特征。</p>
<p><img src="/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/R-CNN.png" alt="R-CNN"></p>
<p>1、对输入图像进行选择性搜索，来选取多个高质量的提议区域，通常在多个尺度下选取，并标注类别与真实边界框；</p>
<p>2、选取一个预训练的卷积神经网络，并将其在输出层之前截断，并将每个提议区域变形为网络所需要的尺寸，并通过前向计算输出抽取的提议区域特征；</p>
<p>3、将每个提议区域的特征连同其标注的类别作为一个文本，训练多个支持向量机对目标进行分类，其中每个支持向量机用来判断样本是否属于一个实例；</p>
<p>4、将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。</p>
<h3 id="FAST-R-CNN"><a href="#FAST-R-CNN" class="headerlink" title="FAST R-CNN"></a>FAST R-CNN</h3><p>R-CNN抽取的独立特征常有大量重复计算，利用FAST R-CNN进行简化，</p>
<h3 id="FASTER-R-CNN"><a href="#FASTER-R-CNN" class="headerlink" title="FASTER R-CNN"></a>FASTER R-CNN</h3><p>将选择性搜索替换成区域提议网络，从而减少提议区域的生成数量，以达到较精确的目标检测结果。</p>
<h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h3><p>当训练数据还标注了每个目标在图像上的像素级位置，那么Mask R CNN模型能有效利用这些详尽的标注信息</p>
<h2 id="语义分割和数据集"><a href="#语义分割和数据集" class="headerlink" title="语义分割和数据集"></a>语义分割和数据集</h2><p>语义分割问题：关注如何将图像分割成属于不同语义类别的区域，且均为像素级，相比于锚框更加精确。</p>
<p>图像分割问题：利用像素间相关性将图像分割成若干区域，且训练时并不需要像素有关的标签信息，预测时也无法保证希望得到的语义。</p>
<p>实例分割问题：研究如何识别图像中各个目标实例的像素级区域，不仅要区分语义，还要区分不同目标实例，比如：区分两条同样语义的狗。</p>
<p>Pascal VOC2012数据集</p>
<p>由于语义分割的输出图像和标签在像素上一一对应，所以将图像随机裁剪成固定尺寸而不是缩放。</p>
<h2 id="全卷积网络FCN"><a href="#全卷积网络FCN" class="headerlink" title="全卷积网络FCN"></a>全卷积网络FCN</h2><p>FCN实现了从图像像素到像素类别的变换；FCN通过转置卷积层，将中间层特征图的高、宽变换回输入图像的尺寸，从而令预测结果与输入图像在空间维上一一对应。</p>
<h3 id="转置卷积层"><a href="#转置卷积层" class="headerlink" title="转置卷积层"></a>转置卷积层</h3><h3 id="构造模型"><a href="#构造模型" class="headerlink" title="构造模型"></a>构造模型</h3><p>1、先使用卷积神经网络来抽取图像特征；</p>
<p>2、通过1X1卷积层将通道数变换成类别个数；</p>
<p>3、通过转置卷积层，将特征图的高、宽变换为输入图像的尺寸，使模型输出与输入图像的高、宽相同，并在空间位置一一对应，最终输出的通道中包含了该空间位置像素级别的类别预测；</p>
<h2 id="样式迁移"><a href="#样式迁移" class="headerlink" title="样式迁移"></a>样式迁移</h2><p>使用卷积神经网络自动将某图像中的样式应用在另一图像上，两张输入图像：内容图像、样式图像。</p>
<h3 id="具体实施"><a href="#具体实施" class="headerlink" title="具体实施"></a>具体实施</h3><p><img src="/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB.png" alt="样式迁移"></p>
<p>1、初始化合成图像，一般初始化成内容图像，该图像便是样式迁移过程中需要迭代的模型参数。</p>
<p>2、选择一个预训练的卷积网络来抽取图像的特征，其中模型参数在训练时无需更新，深度神经网络凭借多个层级逐级抽取图像的特征，可以选择其中某些层的输出作为内容特征；</p>
<p>3、正向传播计算样式迁移的损失函数，通过反向传播迭代模型参数，即不断更新合成图像。</p>
<h3 id="预处理和后处理图像"><a href="#预处理和后处理图像" class="headerlink" title="预处理和后处理图像"></a>预处理和后处理图像</h3><p>预处理：在RGB三个通道分别做标准化，将结果变换成输入形式；</p>
<p>后处理：将输出图像中的像素值还原回标准化之前值；</p>
<h3 id="抽取特征"><a href="#抽取特征" class="headerlink" title="抽取特征"></a>抽取特征</h3><p>使用基于ImageNet数据集训练的VGG-19模型来抽取图像特征；</p>
<h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>内容损失：利用平方误差函数衡量合成图像与样式图像在内容上差异；</p>
<p>样式损失：利用平方误差函数衡量合成图像与样式图像在样式上差异；</p>
<p>总变差损失：用于降噪，使合成图像中噪点（特别亮或特别暗的颗粒像素）减少。</p>
<p>损失函数为以上三者的加权和。</p>

    </div>
    
    
    
    
    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>
        <div class="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="Li Yudong 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Li Yudong
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2020/08/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" title="计算机视觉">http://yoursite.com/2020/08/28/计算机视觉/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

    
      <footer class="post-footer">
    
        

    
        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" rel="prev" title="优化算法与计算性能">
      <i class="fa fa-chevron-left"></i> 优化算法与计算性能
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/29/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="next" title="自然语言处理">
      自然语言处理 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF"><span class="nav-number">1.</span> <span class="nav-text">图像增广</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E5%A2%9E%E5%B9%BF%E5%90%8E%E5%9B%BE%E5%83%8F%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%EF%BC%9A"><span class="nav-number">1.1.</span> <span class="nav-text">用增广后图像训练模型：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%BE%AE%E8%B0%83"><span class="nav-number">2.</span> <span class="nav-text">图像微调</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%83%AD%E7%8B%97%E8%AF%86%E5%88%AB"><span class="nav-number">2.1.</span> <span class="nav-text">热狗识别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%BE%B9%E7%95%8C%E6%A1%86"><span class="nav-number">3.</span> <span class="nav-text">目标检测与边界框</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E9%85%8D%E7%9C%9F%E5%AE%9E%E8%BE%B9%E7%95%8C%E6%A1%86"><span class="nav-number">3.1.</span> <span class="nav-text">分配真实边界框</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6"><span class="nav-number">3.2.</span> <span class="nav-text">非极大值抑制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B"><span class="nav-number">3.3.</span> <span class="nav-text">单发多框检测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B1%BB%E5%88%AB%E9%A2%84%E6%B5%8B%E5%B1%82"><span class="nav-number">3.3.1.</span> <span class="nav-text">类别预测层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BE%B9%E7%95%8C%E9%A2%84%E6%B5%8B%E5%B1%82"><span class="nav-number">3.3.2.</span> <span class="nav-text">边界预测层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%9A%84%E9%A2%84%E6%B5%8B"><span class="nav-number">3.3.3.</span> <span class="nav-text">连接多尺度的预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E3%80%81%E5%AE%BD%E5%87%8F%E5%8D%8A%E5%9D%97"><span class="nav-number">3.3.4.</span> <span class="nav-text">高、宽减半块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E5%9D%97"><span class="nav-number">3.3.5.</span> <span class="nav-text">基础网络块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.6.</span> <span class="nav-text">完整的模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.4.</span> <span class="nav-text">单发多框检测训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B9%B6%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%9B"><span class="nav-number">3.4.1.</span> <span class="nav-text">1、读取数据集并初始化；</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%84%E4%BB%B7%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="nav-number">3.4.2.</span> <span class="nav-text">2、定义损失函数与评价函数：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.4.3.</span> <span class="nav-text">3、训练模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E9%A2%84%E6%B5%8B%E7%9B%AE%E6%A0%87"><span class="nav-number">3.4.4.</span> <span class="nav-text">4、预测目标</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8C%BA%E5%9F%9F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CR-CNN"><span class="nav-number">4.</span> <span class="nav-text">区域卷积神经网络R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#FAST-R-CNN"><span class="nav-number">4.1.</span> <span class="nav-text">FAST R-CNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FASTER-R-CNN"><span class="nav-number">4.2.</span> <span class="nav-text">FASTER R-CNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mask-R-CNN"><span class="nav-number">4.3.</span> <span class="nav-text">Mask R-CNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.</span> <span class="nav-text">语义分割和数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN"><span class="nav-number">6.</span> <span class="nav-text">全卷积网络FCN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">6.1.</span> <span class="nav-text">转置卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%84%E9%80%A0%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.2.</span> <span class="nav-text">构造模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB"><span class="nav-number">7.</span> <span class="nav-text">样式迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E6%96%BD"><span class="nav-number">7.1.</span> <span class="nav-text">具体实施</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E5%90%8E%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F"><span class="nav-number">7.2.</span> <span class="nav-text">预处理和后处理图像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8A%BD%E5%8F%96%E7%89%B9%E5%BE%81"><span class="nav-number">7.3.</span> <span class="nav-text">抽取特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">7.4.</span> <span class="nav-text">定义损失函数</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Li Yudong"
      src="/images/author.jpg">
  <p class="site-author-name" itemprop="name">Li Yudong</p>
  <div class="site-description" itemprop="description">请乐观，请珍惜</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/tiarmor1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;tiarmor1" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1157019137@qq.com" title="E-Mail → mailto:1157019137@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Yudong</span>
</div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib1/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib1/anime.min.js"></script>
  <script src="/lib1/velocity/velocity.min.js"></script>
  <script src="/lib1/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  
   <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
   <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
   <script type="text/javascript" src="/js/fireworks.js"></script>
  
</body>
</html>

